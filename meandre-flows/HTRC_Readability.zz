#
# Generated by RDF2ZZConverter v1.4.9.8618 on Tue Aug 27 19:35:58 CDT 2013
#
# @name 	HTRC_Readability
# @description 	<br>
# @creator 	admin
# @date 	Tue Aug 27 19:35:40 CDT 2013
# @rights 	UIUC/NCSA Open Source License
# @tags 	readability, htrc
# @uri  	meandre://htrc.illinois.edu/flows/htrc_readability/
#

#
# Specify component imports
#
# TODO: Add component import statement(s) here
# Example: import <URL>   (replace 'URL' with the correct location)
import <http://repository.seasr.org/Meandre/Locations/Latest/Components/repository_components.nt>
import <http://repository.seasr.org/Meandre/Locations/Latest/HTRC_Components/repository_components.nt>

#
# Create the component aliases
#
alias <meandre://seasr.org/components/foundry/tuple-value-to-string> as TUPLE_VALUE_TO_STRING
alias <meandre://seasr.org/components/htrc/htrc-page-retriever> as HTRC_PAGE_RETRIEVER
alias <meandre://seasr.org/components/foundry/read-text> as READ_TEXT
alias <meandre://seasr.org/components/foundry/flesch-kincaid-readability-measure> as FLESCH_KINCAID_READABILITY_MEASURE
alias <meandre://seasr.org/components/foundry/push-text> as PUSH_TEXT
alias <meandre://seasr.org/components/foundry/write-to-file> as WRITE_TO_FILE
alias <meandre://seasr.org/components/foundry/random-sample> as RANDOM_SAMPLE
alias <meandre://seasr.org/components/foundry/search-text> as SEARCH_TEXT
alias <meandre://seasr.org/components/foundry/flow-parameter> as FLOW_PARAMETER
alias <meandre://seasr.org/components/foundry/strings-to-java-string> as STRINGS_TO_JAVA_STRING
alias <meandre://seasr.org/components/foundry/fork-x2> as FORK_X2
alias <meandre://seasr.org/components/foundry/csv-to-tuple> as CSV_TO_TUPLE
alias <meandre://seasr.org/components/foundry/text-accumulator> as TEXT_ACCUMULATOR
alias <meandre://seasr.org/components/foundry/text-cleaner> as TEXT_CLEANER
alias <meandre://seasr.org/components/foundry/trigger-message> as TRIGGER_MESSAGE
alias <meandre://seasr.org/components/foundry/universal-text-extractor> as UNIVERSAL_TEXT_EXTRACTOR
alias <meandre://seasr.org/components/foundry/text-replacement> as TEXT_REPLACEMENT
alias <meandre://seasr.org/components/foundry/to-lowercase> as TO_LOWERCASE
alias <meandre://seasr.org/components/foundry/stream-delimiter-filter> as STREAM_DELIMITER_FILTER

#
# Create the component instances
#
stream_delimiter_filter = STREAM_DELIMITER_FILTER()
read_text = READ_TEXT()
trigger_message = TRIGGER_MESSAGE()
flesch_kincaid_readability_measure = FLESCH_KINCAID_READABILITY_MEASURE()
search_text = SEARCH_TEXT()
text_replacement = TEXT_REPLACEMENT()
stream_delimiter_filter_2 = STREAM_DELIMITER_FILTER()
text_cleaner_2 = TEXT_CLEANER()
write_to_file = WRITE_TO_FILE()
push_text_2 = PUSH_TEXT()
flow_parameter = FLOW_PARAMETER()
stream_delimiter_filter_3 = STREAM_DELIMITER_FILTER()
universal_text_extractor_2 = UNIVERSAL_TEXT_EXTRACTOR()
random_sample = RANDOM_SAMPLE()
strings_to_java_string = STRINGS_TO_JAVA_STRING()
text_accumulator = TEXT_ACCUMULATOR()
csv_to_tuple = CSV_TO_TUPLE()
text_cleaner = TEXT_CLEANER()
htrc_page_retriever = HTRC_PAGE_RETRIEVER()
flow_parameter_2 = FLOW_PARAMETER()
text_accumulator_2 = TEXT_ACCUMULATOR()
tuple_value_to_string = TUPLE_VALUE_TO_STRING()
to_lowercase = TO_LOWERCASE()
search_text_2 = SEARCH_TEXT()
fork_x2 = FORK_X2()

#
# Set component properties
#
stream_delimiter_filter._debug_level = "info"
stream_delimiter_filter.advanced_filter = ""
stream_delimiter_filter._stream_id = ""
stream_delimiter_filter._ignore_errors = "false"

read_text.retry_on_timeout = "true"
read_text.read_timeout = "0"
read_text.max_attempts = "1"
read_text._ignore_errors = "false"
read_text.retry_on_http_error = "0"
read_text.retry_delay = "1000"
read_text._debug_level = "info"
read_text.connection_timeout = "0"

trigger_message.reset_on_push = "false"
trigger_message._debug_level = "info"
trigger_message._stream_id = "-1"
trigger_message._ignore_errors = "false"

flesch_kincaid_readability_measure._debug_level = "info"
flesch_kincaid_readability_measure.template = "org/seasr/meandre/components/analytics/text/readability/FleschKincaidReadabilityMeasure.vm"
flesch_kincaid_readability_measure._stream_id = "1"
flesch_kincaid_readability_measure._ignore_errors = "false"

search_text._debug_level = "info"
search_text.expression = "^\\S*"
search_text._stream_id = "0"
search_text.wrap_stream = "false"
search_text._ignore_errors = "false"

text_replacement._debug_level = "info"
text_replacement.ignoreCase = "true"
text_replacement._ignore_errors = "false"

stream_delimiter_filter_2._debug_level = "info"
stream_delimiter_filter_2.advanced_filter = ""
stream_delimiter_filter_2._stream_id = "2"
stream_delimiter_filter_2._ignore_errors = "false"

text_cleaner_2.replace4 = ""
text_cleaner_2.replace3 = ""
text_cleaner_2.replace2 = ""
text_cleaner_2.replace = "|"
text_cleaner_2._ignore_errors = "false"
text_cleaner_2.find4 = ""
text_cleaner_2.find = "\\n"
text_cleaner_2.find3 = ""
text_cleaner_2.find2 = ""
text_cleaner_2._debug_level = "info"

write_to_file._debug_level = "info"
write_to_file.append_timestamp = "false"
write_to_file.append_data_to_file = "false"
write_to_file.default_folder = "/tmp"
write_to_file._ignore_errors = "false"

push_text_2._debug_level = "info"
push_text_2.message = "readability_report.html"
push_text_2._ignore_errors = "false"

flow_parameter.default_value = "/home/lauvil/HTRC/data/volume_id.txt"
flow_parameter._debug_level = "info"
flow_parameter.param_name = "volume_id"
flow_parameter._stream_id = "99"
flow_parameter.wrap_stream = "false"
flow_parameter._ignore_errors = "false"

stream_delimiter_filter_3.advanced_filter = ""
stream_delimiter_filter_3._debug_level = "info"
stream_delimiter_filter_3._stream_id = "2"
stream_delimiter_filter_3._ignore_errors = "false"

universal_text_extractor_2._debug_level = "info"
universal_text_extractor_2.read_timeout = "0"
universal_text_extractor_2.connection_timeout = "0"
universal_text_extractor_2._ignore_errors = "false"

random_sample.seed = "123"
random_sample._debug_level = "info"
random_sample.count = "10"
random_sample._ignore_errors = "false"

strings_to_java_string._debug_level = "info"
strings_to_java_string.separator = "\\n"
strings_to_java_string._ignore_errors = "false"

text_accumulator._debug_level = "info"
text_accumulator.separator = " "
text_accumulator._stream_id = "2"
text_accumulator._ignore_errors = "false"

csv_to_tuple._debug_level = "info"
csv_to_tuple.labels = "volume_id"
csv_to_tuple.header = "false"
csv_to_tuple._ignore_errors = "false"

text_cleaner.replace4 = ""
text_cleaner.replace3 = ""
text_cleaner.replace2 = ""
text_cleaner.replace = ""
text_cleaner._ignore_errors = "false"
text_cleaner.find = "^(.*)\\s"
text_cleaner.find4 = "[^\\p{L}\\p{Z}\\p{S}\\p{N}\\p{P}]"
text_cleaner.find3 = "(?m)--?\\s*$\\s*"
text_cleaner.find2 = "(.*)$"
text_cleaner._debug_level = "info"

htrc_page_retriever.delimiter = "|"
htrc_page_retriever.wrap_stream = "true"
htrc_page_retriever.read_timeout = "0"
htrc_page_retriever.stream_per_volume = "true"
htrc_page_retriever._ignore_errors = "false"
htrc_page_retriever.auth_selfsign = "false"
htrc_page_retriever.auth_token = "a6fa7057bfa0e5a9a33411e41ca9bc69"
htrc_page_retriever._stream_id = "2"
htrc_page_retriever.data_api_url = "https://sandbox.htrc.illinois.edu:25443/data-api"
htrc_page_retriever._debug_level = "info"
htrc_page_retriever.connection_timeout = "0"

flow_parameter_2.default_value = "http://repository.seasr.org/Datasets/Text/ngram_corrections.txt"
flow_parameter_2._debug_level = "info"
flow_parameter_2.param_name = "replacement_rules_url"
flow_parameter_2._stream_id = "99"
flow_parameter_2._ignore_errors = "false"
flow_parameter_2.wrap_stream = "false"

text_accumulator_2._debug_level = "info"
text_accumulator_2.separator = " "
text_accumulator_2._stream_id = "2"
text_accumulator_2._ignore_errors = "false"

tuple_value_to_string._debug_level = "info"
tuple_value_to_string.attribute = "volume_id"
tuple_value_to_string._ignore_errors = "false"

to_lowercase._debug_level = "info"
to_lowercase._ignore_errors = "false"

search_text_2._debug_level = "info"
search_text_2.expression = "(?:[^|]+\\|?){1,4}"
search_text_2._stream_id = "1"
search_text_2.wrap_stream = "true"
search_text_2._ignore_errors = "false"

fork_x2.replication_mode = "0"
fork_x2._debug_level = "info"
fork_x2.replication_method_name = ""
fork_x2._ignore_errors = "false"

#
# Create the flow by connecting the components
#
@csv_to_tuple_outputs = csv_to_tuple()
@to_lowercase_outputs = to_lowercase()
@random_sample_outputs = random_sample()
@tuple_value_to_string_outputs = tuple_value_to_string()
@flow_parameter_outputs = flow_parameter()
@strings_to_java_string_outputs = strings_to_java_string()
@stream_delimiter_filter_outputs = stream_delimiter_filter()
@trigger_message_outputs = trigger_message()
@text_accumulator_2_outputs = text_accumulator_2()
@push_text_2_outputs = push_text_2()
@read_text_outputs = read_text()
@fork_x2_outputs = fork_x2()
@flesch_kincaid_readability_measure_outputs = flesch_kincaid_readability_measure()
@text_replacement_outputs = text_replacement()
@stream_delimiter_filter_3_outputs = stream_delimiter_filter_3()
@flow_parameter_2_outputs = flow_parameter_2()
@search_text_outputs = search_text()
@stream_delimiter_filter_2_outputs = stream_delimiter_filter_2()
@text_cleaner_outputs = text_cleaner() [+AUTO!]
@text_cleaner_2_outputs = text_cleaner_2()
@universal_text_extractor_2_outputs = universal_text_extractor_2()
@htrc_page_retriever_outputs = htrc_page_retriever()
@search_text_2_outputs = search_text_2()
@text_accumulator_outputs = text_accumulator()

to_lowercase(text: stream_delimiter_filter_2_outputs.object)
random_sample(text: strings_to_java_string_outputs.java_string)
csv_to_tuple(text: read_text_outputs.text)
tuple_value_to_string(
	tuples: csv_to_tuple_outputs.tuples;
	meta_tuple: csv_to_tuple_outputs.meta_tuple
)
strings_to_java_string(text: tuple_value_to_string_outputs.text)
stream_delimiter_filter(object: flesch_kincaid_readability_measure_outputs.html)
trigger_message(
	trigger: to_lowercase_outputs.text;
	object: universal_text_extractor_2_outputs.text
)
text_accumulator_2(text: htrc_page_retriever_outputs.volume_id)
fork_x2(object: search_text_outputs.text_found)
flesch_kincaid_readability_measure(
	location: fork_x2_outputs.object2;
	text: text_replacement_outputs.text;
	document_title: fork_x2_outputs.object
)
read_text(location: flow_parameter_outputs.text)
stream_delimiter_filter_3(object: text_accumulator_2_outputs.text)
text_replacement(
	mapData: trigger_message_outputs.object;
	text: trigger_message_outputs.trigger
)
stream_delimiter_filter_2(object: text_accumulator_outputs.text)
search_text(text: stream_delimiter_filter_3_outputs.object)
text_cleaner(text: htrc_page_retriever_outputs.text)
text_cleaner_2(text: random_sample_outputs.text)
write_to_file(
	location: push_text_2_outputs.text;
	data: stream_delimiter_filter_outputs.object
)
htrc_page_retriever(volume_id_list: search_text_2_outputs.text_found)
universal_text_extractor_2(location: flow_parameter_2_outputs.text)
search_text_2(text: text_cleaner_2_outputs.text)
text_accumulator(text: text_cleaner_outputs.text)

