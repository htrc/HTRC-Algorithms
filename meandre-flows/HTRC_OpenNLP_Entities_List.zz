#
# Generated by RDF2ZZConverter v1.4.11.8693M on Mon Mar 23 12:09:18 CDT 2015
#
# @name 	HTRC_OpenNLP_Entities_List
# @description 	<br>
# @creator 	admin
# @date 	Mon Mar 23 12:07:47 CDT 2015
# @rights 	UIUC/NCSA Open Source License
# @tags 	nlp, entities, htrc, entity
# @uri  	meandre://htrc.illinois.edu/flows/htrc_opennlp_entities_list/
#

#
# Specify component imports
#
# TODO: Add component import statement(s) here
# Example: import <URL>   (replace 'URL' with the correct location)
import <http://dev5.informatics.illinois.edu:1714/public/services/repository.ttl>
#
# Create the component aliases
#
alias <meandre://seasr.org/components/foundry/opennlp-sentence-detector> as OPENNLP_SENTENCE_DETECTOR
alias <meandre://seasr.org/components/foundry/csv-to-tuple> as CSV_TO_TUPLE
alias <meandre://seasr.org/components/foundry/tuple-value-to-string> as TUPLE_VALUE_TO_STRING
alias <meandre://seasr.org/components/foundry/opennlp-named-entity> as OPENNLP_NAMED_ENTITY
alias <meandre://seasr.org/components/foundry/add-tuple-attribute> as ADD_TUPLE_ATTRIBUTE
alias <meandre://seasr.org/components/foundry/search-text> as SEARCH_TEXT
alias <meandre://seasr.org/components/foundry/tuple-to-html> as TUPLE_TO_HTML
alias <meandre://seasr.org/components/foundry/text-cleaner> as TEXT_CLEANER
alias <meandre://seasr.org/components/foundry/write-to-file> as WRITE_TO_FILE
alias <meandre://seasr.org/components/foundry/strings-to-java-string> as STRINGS_TO_JAVA_STRING
alias <meandre://seasr.org/components/foundry/push-text> as PUSH_TEXT
alias <meandre://seasr.org/components/foundry/flow-parameter> as FLOW_PARAMETER
alias <meandre://seasr.org/components/foundry/random-sample> as RANDOM_SAMPLE
alias <meandre://seasr.org/components/foundry/tuple-aggregator> as TUPLE_AGGREGATOR
alias <meandre://seasr.org/components/htrc/htrc-page-retriever> as HTRC_PAGE_RETRIEVER
alias <meandre://seasr.org/components/foundry/read-text> as READ_TEXT
alias <meandre://seasr.org/components/foundry/opennlp-sentence-tokenizer> as OPENNLP_SENTENCE_TOKENIZER
alias <meandre://seasr.org/components/foundry/stream-delimiter-filter> as STREAM_DELIMITER_FILTER

#
# Create the component instances
#
flow_parameter = FLOW_PARAMETER()
random_sample = RANDOM_SAMPLE()
opennlp_sentence_tokenizer = OPENNLP_SENTENCE_TOKENIZER()
strings_to_java_string = STRINGS_TO_JAVA_STRING()
opennlp_sentence_detector = OPENNLP_SENTENCE_DETECTOR()
tuple_aggregator = TUPLE_AGGREGATOR()
add_tuple_attribute_2 = ADD_TUPLE_ATTRIBUTE()
search_text = SEARCH_TEXT()
push_text = PUSH_TEXT()
opennlp_named_entity = OPENNLP_NAMED_ENTITY()
text_cleaner = TEXT_CLEANER()
add_tuple_attribute = ADD_TUPLE_ATTRIBUTE()
htrc_page_retriever = HTRC_PAGE_RETRIEVER()
text_cleaner_2 = TEXT_CLEANER()
stream_delimiter_filter = STREAM_DELIMITER_FILTER()
tuple_value_to_string = TUPLE_VALUE_TO_STRING()
write_to_file = WRITE_TO_FILE()
csv_to_tuple = CSV_TO_TUPLE()
tuple_to_html = TUPLE_TO_HTML()
read_text = READ_TEXT()

#
# Set component properties
#
flow_parameter.default_value = "/home/lauvil/HTRC/data/volume_id.txt"
flow_parameter._debug_level = "info"
flow_parameter.param_name = "volume_id"
flow_parameter._stream_id = "99"
flow_parameter.wrap_stream = "false"
flow_parameter._ignore_errors = "false"

random_sample.seed = "123"
random_sample._debug_level = "info"
random_sample.count = "10"
random_sample._ignore_errors = "false"

opennlp_sentence_tokenizer._debug_level = "info"
opennlp_sentence_tokenizer.lang_code = "en"
opennlp_sentence_tokenizer._ignore_errors = "true"

strings_to_java_string._debug_level = "info"
strings_to_java_string.separator = "\\n"
strings_to_java_string._ignore_errors = "false"

opennlp_sentence_detector._debug_level = "info"
opennlp_sentence_detector.lang_code = "en"
opennlp_sentence_detector.remove_newline = "false"
opennlp_sentence_detector._ignore_errors = "true"

tuple_aggregator._debug_level = "info"
tuple_aggregator._stream_id = "1"
tuple_aggregator._ignore_errors = "false"

add_tuple_attribute_2._debug_level = "info"
add_tuple_attribute_2.attribute_name = "volume_id"
add_tuple_attribute_2._ignore_errors = "false"

search_text._debug_level = "info"
search_text._stream_id = "1"
search_text.expression = "(?:[^|]+\\|?){1,4}"
search_text._ignore_errors = "false"
search_text.wrap_stream = "true"

push_text._debug_level = "info"
push_text.message = "named_entity_list.html"
push_text._ignore_errors = "false"

opennlp_named_entity._debug_level = "info"
opennlp_named_entity.entity_types = "person"
opennlp_named_entity.lang_code = "en"
opennlp_named_entity._ignore_errors = "true"

text_cleaner.replace4 = ""
text_cleaner.replace3 = ""
text_cleaner.replace2 = ""
text_cleaner.replace = ""
text_cleaner._ignore_errors = "false"
text_cleaner.find = "^(.*)\\s"
text_cleaner.find4 = ""
text_cleaner.find3 = "(?m)--?\\s*$\\s*"
text_cleaner.find2 = "(.*)$"
text_cleaner._debug_level = "info"

add_tuple_attribute._debug_level = "info"
add_tuple_attribute.attribute_name = "page_id"
add_tuple_attribute._ignore_errors = "false"

htrc_page_retriever.delimiter = "|"
htrc_page_retriever.wrap_stream = "false"
htrc_page_retriever.read_timeout = "0"
htrc_page_retriever.stream_per_volume = "false"
htrc_page_retriever._ignore_errors = "false"
htrc_page_retriever.auth_selfsign = "false"
htrc_page_retriever.auth_token = "a6fa7057bfa0e5a9a33411e41ca9bc69"
htrc_page_retriever._stream_id = "99"
htrc_page_retriever.data_api_url = "https://sandbox.htrc.illinois.edu:25443/data-api"
htrc_page_retriever.connection_timeout = "0"
htrc_page_retriever._debug_level = "info"

text_cleaner_2.replace4 = ""
text_cleaner_2.replace3 = ""
text_cleaner_2.replace2 = ""
text_cleaner_2.replace = "|"
text_cleaner_2._ignore_errors = "false"
text_cleaner_2.find = "\\n"
text_cleaner_2.find4 = ""
text_cleaner_2.find3 = ""
text_cleaner_2.find2 = ""
text_cleaner_2._debug_level = "info"

stream_delimiter_filter._debug_level = "info"
stream_delimiter_filter.advanced_filter = ""
stream_delimiter_filter._stream_id = ""
stream_delimiter_filter._ignore_errors = "false"

tuple_value_to_string._debug_level = "info"
tuple_value_to_string.attribute = "volume_id"
tuple_value_to_string._ignore_errors = "false"

write_to_file._debug_level = "info"
write_to_file.append_timestamp = "false"
write_to_file.append_data_to_file = "false"
write_to_file.default_folder = "/tmp"
write_to_file._ignore_errors = "false"

csv_to_tuple._debug_level = "info"
csv_to_tuple.header = "false"
csv_to_tuple._ignore_errors = "false"
csv_to_tuple.labels = "volume_id"

tuple_to_html._debug_level = "info"
tuple_to_html.properties = ""
tuple_to_html.css = ""
tuple_to_html.template = "org/seasr/meandre/components/tools/tuples/TupleToHTML.vm"
tuple_to_html._ignore_errors = "false"

read_text.retry_on_timeout = "true"
read_text.read_timeout = "0"
read_text.max_attempts = "1"
read_text._ignore_errors = "false"
read_text.retry_on_http_error = "0"
read_text.retry_delay = "1000"
read_text.connection_timeout = "0"
read_text._debug_level = "info"

#
# Create the flow by connecting the components
#
@flow_parameter_outputs = flow_parameter()
@opennlp_sentence_detector_outputs = opennlp_sentence_detector() [+AUTO!]
@random_sample_outputs = random_sample()
@tuple_to_html_outputs = tuple_to_html()
@opennlp_named_entity_outputs = opennlp_named_entity() [+AUTO!]
@text_cleaner_outputs = text_cleaner()
@add_tuple_attribute_2_outputs = add_tuple_attribute_2()
@text_cleaner_2_outputs = text_cleaner_2()
@tuple_aggregator_outputs = tuple_aggregator()
@stream_delimiter_filter_outputs = stream_delimiter_filter()
@strings_to_java_string_outputs = strings_to_java_string()
@read_text_outputs = read_text()
@opennlp_sentence_tokenizer_outputs = opennlp_sentence_tokenizer() [+AUTO!]
@htrc_page_retriever_outputs = htrc_page_retriever()
@tuple_value_to_string_outputs = tuple_value_to_string()
@push_text_outputs = push_text()
@csv_to_tuple_outputs = csv_to_tuple()
@add_tuple_attribute_outputs = add_tuple_attribute()
@search_text_outputs = search_text()

opennlp_sentence_detector(text: text_cleaner_outputs.text)
random_sample(text: strings_to_java_string_outputs.java_string)
tuple_to_html(
	meta_tuple: tuple_aggregator_outputs.meta_tuple;
	tuples: tuple_aggregator_outputs.tuples
)
text_cleaner(text: htrc_page_retriever_outputs.text)
opennlp_named_entity(tokenized_sentences: opennlp_sentence_tokenizer_outputs.tokenized_sentences)
add_tuple_attribute_2(
	tuples: opennlp_named_entity_outputs.tuples;
	meta_tuple: opennlp_named_entity_outputs.meta_tuple;
	attribute: htrc_page_retriever_outputs.volume_id
)
write_to_file(
	location: push_text_outputs.text;
	data: stream_delimiter_filter_outputs.object
)
text_cleaner_2(text: random_sample_outputs.text)
stream_delimiter_filter(object: tuple_to_html_outputs.html)
tuple_aggregator(
	meta_tuple: add_tuple_attribute_outputs.meta_tuple;
	tuples: add_tuple_attribute_outputs.tuples
)
strings_to_java_string(text: tuple_value_to_string_outputs.text)
read_text(location: flow_parameter_outputs.text)
opennlp_sentence_tokenizer(sentences: opennlp_sentence_detector_outputs.sentences)
htrc_page_retriever(volume_id_list: search_text_outputs.text_found)
tuple_value_to_string(
	tuples: csv_to_tuple_outputs.tuples;
	meta_tuple: csv_to_tuple_outputs.meta_tuple
)
csv_to_tuple(text: read_text_outputs.text)
add_tuple_attribute(
	tuples: add_tuple_attribute_2_outputs.tuples;
	meta_tuple: add_tuple_attribute_2_outputs.meta_tuple;
	attribute: htrc_page_retriever_outputs.page_id
)
search_text(text: text_cleaner_2_outputs.text)

